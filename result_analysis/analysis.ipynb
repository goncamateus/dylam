{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import (\n",
    "    plot_lambdas,\n",
    "    plot_rewards,\n",
    "    plot_result,\n",
    "    plot_result_taxi,\n",
    "    smooth_curve,\n",
    "    FORMATTER,\n",
    "    METHOD_COLORS,\n",
    "    REWARD_RANGES\n",
    ")\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"grid.color\": \"lightgray\"})\n",
    "plt.rc(\"axes\", titlesize=16, titleweight=\"bold\", labelsize=14, labelweight=\"bold\")\n",
    "plt.rc(\"xtick\", labelsize=12)\n",
    "plt.rc(\"ytick\", labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis per Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"Q-Learning\", \"Q-Decomposition\", \"DRQ\", \"Tuned-DRQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"Taxi-v3\",\n",
    "    results,\n",
    "    FORMATTER,\n",
    "    METHOD_COLORS,\n",
    "    \"Efficient Drop-off Rate\",\n",
    "    x_label=\"Number of training episodes\",\n",
    "    smooth_factor=10,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"Fuel\", \"Passenger_Drop_off\", \"Illegal_action\"]\n",
    "}\n",
    "plot_lambdas(\"Taxi-v3\", lambdas, FORMATTER, 1, x_label=\"Number of training episodes\")\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"rew-Fuel\", \"rew-Passenger_Drop_off\", \"rew-Illegal_action\"]\n",
    "}\n",
    "reward_max = REWARD_RANGES[\"Taxi-v3\"][\"r_max\"]\n",
    "reward_min = REWARD_RANGES[\"Taxi-v3\"][\"r_min\"]\n",
    "plot_rewards(\n",
    "    \"Taxi-v3\",\n",
    "    rewards,\n",
    "    reward_max,\n",
    "    reward_min,\n",
    "    FORMATTER,\n",
    "    10,\n",
    "    x_label=\"Number of training episodes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\"DQN\", \"DRQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"LunarLander-v2\",\n",
    "    results,\n",
    "    FORMATTER,\n",
    "    METHOD_COLORS,\n",
    "    \"Landing rate\",\n",
    "    smooth_factor=100,\n",
    "    smooth_factor_min_max=20,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\"Shaping\", \"Power_Linear\", \"Power_Angular\", \"Landing_Rate\"]\n",
    "}\n",
    "plot_lambdas(\"LunarLander-v2\", lambdas, FORMATTER, 1)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\n",
    "        \"rew-Shaping\",\n",
    "        \"rew-Power_Linear\",\n",
    "        \"rew-Power_Angular\",\n",
    "        \"rew-Landing_Rate\",\n",
    "    ]\n",
    "}\n",
    "reward_max = REWARD_RANGES[\"LunarLander-v2\"][\"r_max\"]\n",
    "reward_min = REWARD_RANGES[\"LunarLander-v2\"][\"r_min\"]\n",
    "plot_rewards(\"LunarLander-v2\", rewards, reward_max, reward_min, FORMATTER, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HalfCheetah-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"SAC\", \"DRQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"HalfCheetah-v4\",\n",
    "    results,\n",
    "    FORMATTER,\n",
    "    METHOD_COLORS,\n",
    "    \"Final Position\",\n",
    "    smooth_factor=100,\n",
    "    smooth_factor_min_max=100,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"Run\", \"Control\"]\n",
    "}\n",
    "plot_lambdas(\"HalfCheetah-v4\", lambdas, FORMATTER, 1)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"rew-Run\", \"rew-Control\"]\n",
    "}\n",
    "reward_max = REWARD_RANGES[\"HalfCheetah-v4\"][\"r_max\"]\n",
    "reward_min = REWARD_RANGES[\"HalfCheetah-v4\"][\"r_min\"]\n",
    "plot_rewards(\"HalfCheetah-v4\", rewards, reward_max, reward_min, FORMATTER, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSS-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"VSS/{x}.csv\") for x in [\"SAC\", \"DRQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"VSS-v0\",\n",
    "    results,\n",
    "    FORMATTER,\n",
    "    METHOD_COLORS,\n",
    "    \"Goal rate\",\n",
    "    smooth_factor=500,\n",
    "    smooth_factor_min_max=100,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"VSS/{x}.csv\")\n",
    "    for x in [\"Move_to_ball\", \"Ball_to_goal\", \"Energy\"]\n",
    "}\n",
    "plot_lambdas(\"VSS-v0\", lambdas, FORMATTER, 1)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"VSS/{x}.csv\")\n",
    "    for x in [\"rew-Move_to_ball\", \"rew-Ball_to_goal\", \"rew-Energy\"]\n",
    "}\n",
    "reward_max = REWARD_RANGES[\"VSS-v0\"][\"r_max\"]\n",
    "reward_min = REWARD_RANGES[\"VSS-v0\"][\"r_min\"]\n",
    "plot_rewards(\"VSS-v0\", rewards, reward_max, reward_min, FORMATTER, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dylam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
