{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from yaml import safe_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"grid.color\": \"lightgray\"})\n",
    "plt.rcParams[\"figure.dpi\"] = 600\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True)\n",
    "formatter.set_powerlimits((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_colors = {\n",
    "    \"Q-Learning\": \"orange\",\n",
    "    \"DQN\": \"orange\",\n",
    "    \"SAC\": \"orange\",\n",
    "    \"Baseline\": \"orange\",\n",
    "    \"DyLam\": \"blue\",\n",
    "    \"drQ\": \"green\",\n",
    "    \"GPILS\": \"green\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = safe_load(open(\"../experiments.yml\", \"r\"))\n",
    "reward_ranges = {\n",
    "    value[\"gym_id\"].replace(\"mo-\", \"\"): {\n",
    "        \"r_max\": value[\"r_max\"],\n",
    "        \"r_min\": value[\"r_min\"],\n",
    "    }\n",
    "    for value in params[\"Dylam\"].values()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis per Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing a given signal using a moving average filter (100 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points: np.array, factor: float = 0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(\n",
    "    gym_id,\n",
    "    results: dict,\n",
    "    formatter: ticker.ScalarFormatter,\n",
    "    colors: dict,\n",
    "    y_label: str,\n",
    "    x_label: str = \"Number of training steps\",\n",
    "    smooth_factor_mean: float = 0.9,\n",
    "    smooth_factor_min_max: float = 0.9,\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    for method in results.keys():\n",
    "        mean_key = [\n",
    "            key\n",
    "            for key in results[method].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ][0]\n",
    "        min_key = [key for key in results[method].keys() if key.endswith(\"MIN\")][0]\n",
    "        max_key = [key for key in results[method].keys() if key.endswith(\"MAX\")][0]\n",
    "\n",
    "        x = results[method][\"Step\"]\n",
    "        y = smooth_curve(results[method][mean_key], factor=smooth_factor_mean)\n",
    "        y_min = smooth_curve(results[method][min_key], factor=smooth_factor_min_max)\n",
    "        y_max = smooth_curve(results[method][max_key], factor=smooth_factor_min_max)\n",
    "\n",
    "        # Plot the data using y as the mean continuous line and y_min/y_max as shaded regions\n",
    "        ax.plot(x, y, label=method, color=colors[method])\n",
    "        ax.fill_between(x, y_min, y_max, color=colors[method], alpha=0.2)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label, labelpad=1)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{gym_id}\")\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    plt.savefig(f\"{gym_id}.pdf\", format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambdas(\n",
    "    title, lambdas, formatter, smooth_factor, x_label=\"Number of training steps\"\n",
    "):\n",
    "    COLOR = {\n",
    "        \"0\": \"red\",\n",
    "        \"1\": \"blue\",\n",
    "        \"2\": \"green\",\n",
    "        \"3\": \"orange\",\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    for weight in lambdas.keys():\n",
    "        mean_key = [\n",
    "            key\n",
    "            for key in lambdas[weight].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ][0]\n",
    "\n",
    "        x = lambdas[weight][\"Step\"]\n",
    "        y = smooth_curve(lambdas[weight][mean_key], factor=smooth_factor)\n",
    "        ax.plot(x, y, label=weight.replace(\"_\", \" \"), color=COLOR[mean_key[-1]])\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(r\"$\\lambda$ weights\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{title}\")\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    path = title + \"-weights.pdf\"\n",
    "    plt.savefig(path, format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(\n",
    "    title,\n",
    "    rewards,\n",
    "    reward_max,\n",
    "    reward_min,\n",
    "    formatter,\n",
    "    smooth_factor,\n",
    "    x_label=\"Number of training steps\",\n",
    "):\n",
    "    def normalize_rewards(rew, reward_max, reward_min):\n",
    "        rew = np.array(rew)\n",
    "        abs_max = max(abs(reward_max), abs(reward_min))\n",
    "        rew = rew / abs_max\n",
    "        return rew\n",
    "\n",
    "    PARAM = {\n",
    "        0: (\"red\", (0, (3, 1))),\n",
    "        1: (\"blue\", (0, (3, 4))),\n",
    "        2: (\"green\", (0, (3, 8))),\n",
    "        3: (\"orange\", (0, (3, 12))),\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    normalized_max_rewards = [\n",
    "        normalize_rewards([reward_max[i]], reward_max[i], reward_min[i])\n",
    "        for i in range(len(reward_max))\n",
    "    ]\n",
    "    for i, reward in enumerate(rewards.keys()):\n",
    "        mean_key = [\n",
    "            key\n",
    "            for key in rewards[reward].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ][0]\n",
    "\n",
    "        x = rewards[reward][\"Step\"]\n",
    "        r_max_line = [normalized_max_rewards[i]] * len(x)\n",
    "        ax.plot(x, r_max_line, color=PARAM[i][0], linestyle=PARAM[i][1])\n",
    "        y = smooth_curve(rewards[reward][mean_key], factor=smooth_factor)\n",
    "        y = normalize_rewards(y, reward_max[i], reward_min[i])\n",
    "        ax.plot(x, y, label=reward.replace(\"_\", \" \"), color=PARAM[i][0])\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(\"Cumulative Episode Rewards (Normalized)\", labelpad=1)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    path = title + \"-components.pdf\"\n",
    "    plt.savefig(path, format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\") for x in [\"Q-Learning\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"Taxi-v3\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Passenger dropoff rate\",\n",
    "    x_label=\"Number of training episodes\",\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"Fuel\", \"Passanger_dropoff\", \"Illegal_action\"]\n",
    "}\n",
    "plot_lambdas(\"Taxi-v3\", lambdas, formatter, 0.99, x_label=\"Number of training episodes\")\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"rew-Fuel\", \"rew-Passanger_dropoff\", \"rew-Illegal_action\"]\n",
    "}\n",
    "reward_max = reward_ranges[\"Taxi-v3\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"Taxi-v3\"][\"r_min\"]\n",
    "plot_rewards(\"Taxi-v3\", rewards, reward_max, reward_min, formatter, 0.99, x_label=\"Number of training episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\") for x in [\"DQN\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"LunarLander-v2\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Landing rate\",\n",
    "    smooth_factor_mean=0.99,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\"Shaping\", \"Power_Linear\", \"Power_Angular\", \"Landing_Rate\"]\n",
    "}\n",
    "plot_lambdas(\"LunarLander-v2\", lambdas, formatter, 0.99)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\n",
    "        \"rew-Shaping\",\n",
    "        \"rew-Power_Linear\",\n",
    "        \"rew-Power_Angular\",\n",
    "        \"rew-Landing_Rate\",\n",
    "    ]\n",
    "}\n",
    "reward_max = reward_ranges[\"LunarLander-v2\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"LunarLander-v2\"][\"r_min\"]\n",
    "plot_rewards(\"LunarLander-v2\", rewards, reward_max, reward_min, formatter, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HalfCheetah-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\") for x in [\"SAC\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"HalfCheetah-v4\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Final Position\",\n",
    "    smooth_factor_mean=0.99,\n",
    "    smooth_factor_min_max=0.99,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"Run\", \"Control\"]\n",
    "}\n",
    "plot_lambdas(\"HalfCheetah-v4\", lambdas, formatter, 0.99)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"rew-Run\", \"rew-Control\"]\n",
    "}\n",
    "reward_max = reward_ranges[\"HalfCheetah-v4\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"HalfCheetah-v4\"][\"r_min\"]\n",
    "plot_rewards(\"HalfCheetah-v4\", rewards, reward_max, reward_min, formatter, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSS-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {x.replace(\".csv\", \"\"): pd.read_csv(f\"VSS/{x}.csv\") for x in [\"SAC\", \"DyLam\"]}\n",
    "plot_result(\n",
    "    \"VSS-v0\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Goal rate\",\n",
    "    smooth_factor_mean=0.99,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"VSS/{x}.csv\")\n",
    "    for x in [\"Move_to_ball\", \"Ball_to_goal\", \"Energy\"]\n",
    "}\n",
    "plot_lambdas(\"VSS-v0\", lambdas, formatter, 0.99)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"VSS/{x}.csv\")\n",
    "    for x in [\"rew-Move_to_ball\", \"rew-Ball_to_goal\", \"rew-Energy\"]\n",
    "}\n",
    "reward_max = reward_ranges[\"VSS-v0\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"VSS-v0\"][\"r_min\"]\n",
    "plot_rewards(\"VSS-v0\", rewards, reward_max, reward_min, formatter, 0.99)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
