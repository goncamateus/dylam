{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from yaml import safe_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", rc={\"grid.color\": \"lightgray\"})\n",
    "plt.rcParams[\"figure.dpi\"] = 600\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True)\n",
    "formatter.set_powerlimits((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_colors = {\n",
    "    \"Q-Learning\": \"orange\",\n",
    "    \"DQN\": \"orange\",\n",
    "    \"SAC\": \"orange\",\n",
    "    \"Baseline\": \"orange\",\n",
    "    \"DyLam\": \"blue\",\n",
    "    \"drQ\": \"green\",\n",
    "    \"GPILS\": \"green\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = safe_load(open(\"../experiments.yml\", \"r\"))\n",
    "reward_ranges = {\n",
    "    value[\"gym_id\"].replace(\"mo-\", \"\"): {\n",
    "        \"r_max\": value[\"r_max\"],\n",
    "        \"r_min\": value[\"r_min\"],\n",
    "    }\n",
    "    for value in params[\"Dylam\"].values()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis per Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing a given signal using a moving average filter (100 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points: np.array, factor: int = 100):\n",
    "    cumsum = np.cumsum(np.insert(points, 0, 0))\n",
    "    return (cumsum[factor:] - cumsum[:-factor]) / float(factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(\n",
    "    gym_id,\n",
    "    results: dict,\n",
    "    formatter: ticker.ScalarFormatter,\n",
    "    colors: dict,\n",
    "    y_label: str,\n",
    "    x_label: str = \"Number of training steps\",\n",
    "    smooth_factor: int = 100,\n",
    "    smooth_factor_min_max: int = 100,\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    for method in results.keys():\n",
    "        mean_key = [\n",
    "            key\n",
    "            for key in results[method].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ][0]\n",
    "        min_key = [key for key in results[method].keys() if key.endswith(\"MIN\")][0]\n",
    "        max_key = [key for key in results[method].keys() if key.endswith(\"MAX\")][0]\n",
    "\n",
    "        x = results[method][\"Step\"].loc[smooth_factor-1:]\n",
    "        y = smooth_curve(results[method][mean_key], factor=smooth_factor)\n",
    "        ax.plot(x, y, label=method, color=colors[method])\n",
    "\n",
    "        x = results[method][\"Step\"].loc[smooth_factor_min_max-1:]\n",
    "        y_min = smooth_curve(results[method][min_key], smooth_factor_min_max)\n",
    "        y_max = smooth_curve(results[method][max_key], smooth_factor_min_max)\n",
    "        ax.fill_between(x, y_min, y_max, color=colors[method], alpha=0.2)\n",
    "\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label, labelpad=1)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{gym_id}\")\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    plt.savefig(f\"{gym_id}.pdf\", format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_taxi(\n",
    "    gym_id,\n",
    "    results: dict,\n",
    "    formatter: ticker.ScalarFormatter,\n",
    "    colors: dict,\n",
    "    y_label: str,\n",
    "    x_label: str = \"Number of training steps\",\n",
    "    smooth_factor: int = 100,\n",
    "):\n",
    "    def get_reward(result, keys):\n",
    "        reward = (\n",
    "            result[keys[0]]\n",
    "            - abs(result[keys[1]] / 200)\n",
    "            - abs((result[keys[2]]) / 200) + 0.1\n",
    "        )\n",
    "        reward = np.clip(reward, -1, 1)\n",
    "        return reward\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for method in results.keys():\n",
    "        mean_keys = [\n",
    "            key\n",
    "            for key in results[method].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ]\n",
    "        min_keys = [key for key in results[method].keys() if key.endswith(\"MIN\")]\n",
    "        max_keys = [key for key in results[method].keys() if key.endswith(\"MAX\")]\n",
    "\n",
    "        result_mean = get_reward(results[method], mean_keys)\n",
    "        result_min = get_reward(results[method], min_keys)\n",
    "        result_max = get_reward(results[method], max_keys)\n",
    "\n",
    "        x = results[method][\"Step\"].loc[smooth_factor - 1 :]\n",
    "        y = smooth_curve(result_mean, factor=smooth_factor)\n",
    "        y_min = smooth_curve(result_min, factor=smooth_factor)\n",
    "        y_max = smooth_curve(result_max, factor=smooth_factor)\n",
    "\n",
    "        # Plot the data using y as the mean continuous line and y_min/y_max as shaded regions\n",
    "        ax.plot(x, y, label=method, color=colors[method])\n",
    "        ax.fill_between(x, y_min, y_max, color=colors[method], alpha=0.2)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label, labelpad=1)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{gym_id}\")\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    plt.savefig(f\"{gym_id}.pdf\", format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambdas(\n",
    "    title, lambdas, formatter, smooth_factor, x_label=\"Number of training steps\"\n",
    "):\n",
    "    COLOR = {\n",
    "        0: \"red\",\n",
    "        1: \"blue\",\n",
    "        2: \"green\",\n",
    "        3: \"orange\",\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, weight in enumerate(lambdas.keys()):\n",
    "        mean_key = [\n",
    "            key\n",
    "            for key in lambdas[weight].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ][0]\n",
    "\n",
    "        x = lambdas[weight][\"Step\"].loc[smooth_factor - 1 :]\n",
    "        y = smooth_curve(lambdas[weight][mean_key], factor=smooth_factor)\n",
    "        ax.plot(x, y, label=weight.replace(\"_\", \" \"), color=COLOR[i])\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(r\"$\\lambda$ weights\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{title}\")\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    path = title + \"-weights.pdf\"\n",
    "    plt.savefig(path, format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(\n",
    "    title,\n",
    "    rewards,\n",
    "    reward_max,\n",
    "    reward_min,\n",
    "    formatter,\n",
    "    smooth_factor,\n",
    "    x_label=\"Number of training steps\",\n",
    "):\n",
    "    def normalize_rewards(rew, reward_max, reward_min):\n",
    "        rew = np.array(rew)\n",
    "        abs_max = max(abs(reward_max), abs(reward_min))\n",
    "        rew = rew / abs_max\n",
    "        return rew\n",
    "\n",
    "    PARAM = {\n",
    "        0: (\"red\", (0, (3, 1))),\n",
    "        1: (\"blue\", (0, (3, 4))),\n",
    "        2: (\"green\", (0, (3, 8))),\n",
    "        3: (\"orange\", (0, (3, 12))),\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    normalized_max_rewards = [\n",
    "        normalize_rewards([reward_max[i]], reward_max[i], reward_min[i])\n",
    "        for i in range(len(reward_max))\n",
    "    ]\n",
    "    for i, reward in enumerate(rewards.keys()):\n",
    "        mean_key = [\n",
    "            key\n",
    "            for key in rewards[reward].keys()\n",
    "            if not (\n",
    "                key.startswith(\"Step\") or key.endswith(\"MAX\") or key.endswith(\"MIN\")\n",
    "            )\n",
    "        ][0]\n",
    "\n",
    "        x = rewards[reward][\"Step\"].loc[smooth_factor-1:]\n",
    "        r_max_line = [normalized_max_rewards[i]] * len(x)\n",
    "        ax.plot(x, r_max_line, color=PARAM[i][0], linestyle=PARAM[i][1])\n",
    "        y = smooth_curve(rewards[reward][mean_key], factor=smooth_factor)\n",
    "        y = normalize_rewards(y, reward_max[i], reward_min[i])\n",
    "        ax.plot(x, y, label=reward.replace(\"_\", \" \"), color=PARAM[i][0])\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(\"Cumulative Episode Rewards (Normalized)\", labelpad=1)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    path = title + \"-components.pdf\"\n",
    "    plt.savefig(path, format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"Q-Learning\", \"drQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result_taxi(\n",
    "    \"Taxi-v3\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Efficient Drop-off Rate\",\n",
    "    x_label=\"Number of training episodes\",\n",
    "    smooth_factor=10,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"Fuel\", \"Passenger_Drop-off\", \"Illegal_action\"]\n",
    "}\n",
    "plot_lambdas(\"Taxi-v3\", lambdas, formatter, 1, x_label=\"Number of training episodes\")\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"Taxi/{x}.csv\")\n",
    "    for x in [\"rew-Fuel\", \"rew-Passenger_Drop-off\", \"rew-Illegal_action\"]\n",
    "}\n",
    "reward_max = reward_ranges[\"Taxi-v3\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"Taxi-v3\"][\"r_min\"]\n",
    "plot_rewards(\n",
    "    \"Taxi-v3\",\n",
    "    rewards,\n",
    "    reward_max,\n",
    "    reward_min,\n",
    "    formatter,\n",
    "    10,\n",
    "    x_label=\"Number of training episodes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\"DQN\", \"drQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"LunarLander-v2\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Landing rate\",\n",
    "    smooth_factor=100,\n",
    "    smooth_factor_min_max=20,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\"Shaping\", \"Power_Linear\", \"Power_Angular\", \"Landing_Rate\"]\n",
    "}\n",
    "plot_lambdas(\"LunarLander-v2\", lambdas, formatter, 1)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"LunarLander/{x}.csv\")\n",
    "    for x in [\n",
    "        \"rew-Shaping\",\n",
    "        \"rew-Power_Linear\",\n",
    "        \"rew-Power_Angular\",\n",
    "        \"rew-Landing_Rate\",\n",
    "    ]\n",
    "}\n",
    "reward_max = reward_ranges[\"LunarLander-v2\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"LunarLander-v2\"][\"r_min\"]\n",
    "plot_rewards(\"LunarLander-v2\", rewards, reward_max, reward_min, formatter, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HalfCheetah-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"SAC\", \"drQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"HalfCheetah-v4\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Final Position\",\n",
    "    smooth_factor=100,\n",
    "    smooth_factor_min_max=100,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"Run\", \"Control\"]\n",
    "}\n",
    "plot_lambdas(\"HalfCheetah-v4\", lambdas, formatter, 1)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"HalfCheetah/{x}.csv\")\n",
    "    for x in [\"rew-Run\", \"rew-Control\"]\n",
    "}\n",
    "reward_max = reward_ranges[\"HalfCheetah-v4\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"HalfCheetah-v4\"][\"r_min\"]\n",
    "plot_rewards(\"HalfCheetah-v4\", rewards, reward_max, reward_min, formatter, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSS-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"VSS/{x}.csv\") for x in [\"SAC\", \"drQ\", \"DyLam\"]\n",
    "}\n",
    "plot_result(\n",
    "    \"VSS-v0\",\n",
    "    results,\n",
    "    formatter,\n",
    "    method_colors,\n",
    "    \"Goal rate\",\n",
    "    smooth_factor=500,\n",
    "    smooth_factor_min_max=100,\n",
    ")\n",
    "\n",
    "lambdas = {\n",
    "    x.replace(\".csv\", \"\"): pd.read_csv(f\"VSS/{x}.csv\")\n",
    "    for x in [\"Move_to_ball\", \"Ball_to_goal\", \"Energy\"]\n",
    "}\n",
    "plot_lambdas(\"VSS-v0\", lambdas, formatter, 1)\n",
    "\n",
    "rewards = {\n",
    "    x.replace(\"rew-\", \"\"): pd.read_csv(f\"VSS/{x}.csv\")\n",
    "    for x in [\"rew-Move_to_ball\", \"rew-Ball_to_goal\", \"rew-Energy\"]\n",
    "}\n",
    "reward_max = reward_ranges[\"VSS-v0\"][\"r_max\"]\n",
    "reward_min = reward_ranges[\"VSS-v0\"][\"r_min\"]\n",
    "plot_rewards(\"VSS-v0\", rewards, reward_max, reward_min, formatter, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
